{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b1ee8fb",
   "metadata": {},
   "source": [
    "## Due date: 5/1/2025\n",
    "### Nandini Doddi & Jeslyn Miranda\n",
    "For your group project, you are requested to do a complete process of machine learning, which includes\n",
    "Feature extraction, classification, and analysis.\n",
    "You can access the data that we are working with on Canvas -> Modules =-> Subcellular Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d29d433",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ saved data/clean_gramneg.csv   shape=(1456, 3)\n",
      "✓ saved data/clean_grampos.csv   shape=(523, 3)\n"
     ]
    }
   ],
   "source": [
    "#loads raw CSVs → keep ID / Fold / Sequence → save cleaned CSVs.\n",
    "import pandas as pd  # table helper\n",
    "\n",
    "def clean_csv(src, dst, keep_cols):\n",
    "    df = pd.read_csv(src, header=None)      # 1. read the CSV with no header row\n",
    "    df = df[keep_cols]                      # 2. keep only the columns we list\n",
    "    df.columns = [\"ID\", \"Fold\", \"Sequence\"] # 3. give those columns clear names\n",
    "    df[\"ID\"] = df[\"ID\"].str.lstrip(\">\")     # 4. remove the '>' at the start of each ID\n",
    "    df.dropna(inplace=True)                 # 5. delete rows missing any value\n",
    "    df.to_csv(dst, index=False)             # 6. write the tidy table to a new file\n",
    "    print(f\"✓ saved {dst}   shape={df.shape}\")  # 7. show where it went and its size\n",
    "\n",
    "# clean Gram-negative (has duplicate columns, so we keep 2, 1, 5)\n",
    "clean_csv(\"data/n-data.csv\", \"data/clean_gramneg.csv\", [2, 1, 5])\n",
    "\n",
    "# clean Gram-positive (no duplicates, so we keep 2, 1, 3)\n",
    "clean_csv(\"data/g_data.csv\", \"data/clean_grampos.csv\", [2, 1, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99496a19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis for Gram-negative dataset:\n",
      "1. Number of proteins: 1456\n",
      "2. Number of Labels: 8\n",
      "\n",
      "3. Proteins in each class:\n",
      "Label\n",
      "Fold1    557\n",
      "Fold3    410\n",
      "Fold8    180\n",
      "Fold4    133\n",
      "Fold2    124\n",
      "Fold5     32\n",
      "Fold6     12\n",
      "Fold7      8\n",
      "Name: count, dtype: int64\n",
      "\n",
      "4. Average length per class:\n",
      "Label\n",
      "Fold1    361.75\n",
      "Fold2    488.10\n",
      "Fold3    373.40\n",
      "Fold4    472.39\n",
      "Fold5    203.25\n",
      "Fold6    480.33\n",
      "Fold7    432.50\n",
      "Fold8    360.48\n",
      "Name: Length, dtype: float64\n",
      "\n",
      "5. Max and Min protein length per class:\n",
      "        max  min\n",
      "Label           \n",
      "Fold1  2832   50\n",
      "Fold2  2249   55\n",
      "Fold3  1486   67\n",
      "Fold4  1849   58\n",
      "Fold5   357   70\n",
      "Fold6   685  249\n",
      "Fold7  1486  167\n",
      "Fold8  1015   82\n",
      "\n",
      "\n",
      "Analysis for Gram-positive dataset:\n",
      "1. Number of proteins: 523\n",
      "2. Number of Labels: 4\n",
      "\n",
      "3. Proteins in each class:\n",
      "Label\n",
      "Fold3    208\n",
      "Fold1    174\n",
      "Fold4    123\n",
      "Fold2     18\n",
      "Name: count, dtype: int64\n",
      "\n",
      "4. Average length per class:\n",
      "Label\n",
      "Fold1    434.18\n",
      "Fold2    759.22\n",
      "Fold3    393.80\n",
      "Fold4    410.19\n",
      "Name: Length, dtype: float64\n",
      "\n",
      "5. Max and Min protein length per class:\n",
      "        max  min\n",
      "Label           \n",
      "Fold1  2334   87\n",
      "Fold2  2313  135\n",
      "Fold3  1437   67\n",
      "Fold4  1628   55\n"
     ]
    }
   ],
   "source": [
    "def analyze_protein_data(file_path, dataset_name):\n",
    "    data = pd.read_csv(file_path, header=None)\n",
    "\n",
    "    if data.shape[1] == 6:\n",
    "        data.columns = [\"Fold\", \"Label\", \"ID\", \"SeqCol1\", \"Blank\", \"Sequence\"]\n",
    "    elif data.shape[1] == 4:\n",
    "        data.columns = [\"ID\", \"Label\", \"Extra\", \"Sequence\"]\n",
    "    else:\n",
    "        raise ValueError(\"Unexpected columns\")\n",
    "\n",
    "    data = data.dropna(subset=[\"Sequence\", \"Label\"])\n",
    "\n",
    "    print(f\"Analysis for {dataset_name} dataset:\")\n",
    "\n",
    "    # Number of proteins\n",
    "    print(f\"1. Number of proteins: {len(data)}\")\n",
    "\n",
    "    # Number of unique labels\n",
    "    print(f\"2. Number of Labels: {data['Label'].nunique()}\")\n",
    "\n",
    "    # Proteins in each class\n",
    "    print(\"\\n3. Proteins in each class:\")\n",
    "    print(data['Label'].value_counts())\n",
    "\n",
    "    # Protein lengths\n",
    "    data[\"Length\"] = data[\"Sequence\"].str.len()\n",
    "\n",
    "    # Average length\n",
    "    \n",
    "    print(\"\\n4. Average length per class:\")\n",
    "    print(data.groupby(\"Label\")[\"Length\"].mean().round(2))\n",
    "\n",
    "    # Max and Min lengths\n",
    "    print(\"\\n5. Max and Min protein length per class:\")\n",
    "    print(data.groupby(\"Label\")[\"Length\"].agg(['max', 'min']))\n",
    "\n",
    "# Run for both datasets\n",
    "analyze_protein_data(\"data/n-data.csv\", \"Gram-negative\")\n",
    "print(\"\\n\")\n",
    "analyze_protein_data(\"data/g_data.csv\", \"Gram-positive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "14a5d29f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ saved data/features_gramneg.csv  (rows=1456)\n",
      "✓ saved data/features_grampos.csv  (rows=523)\n"
     ]
    }
   ],
   "source": [
    "# Reads the cleaned CSVs, creates 20 amino-acid fraction features + Length,\n",
    "# and saves the new feature tables in the data/ folder.\n",
    "import pandas as pd\n",
    "from collections import Counter   # for counting letters\n",
    "\n",
    "AA = list(\"ACDEFGHIKLMNPQRSTVWY\")  # fixed order of the 20 amino acids\n",
    "\n",
    "# Convert ONE sequence into:\n",
    "#   [Frac_A, Frac_C, …, Frac_Y, Length]\n",
    "def seq_to_row(seq):\n",
    "    seq   = seq.upper()\n",
    "    length = len(seq)\n",
    "    counts = Counter(seq)\n",
    "    return [counts.get(a, 0) / length for a in AA] + [length]\n",
    "\n",
    "# Build a full feature table from a cleaned CSV and write it out\n",
    "def make_features(src, dst):\n",
    "    df = pd.read_csv(src)                             # load cleaned file\n",
    "    feats = df[\"Sequence\"].apply(seq_to_row)          # features for every row\n",
    "    cols = [f\"Frac_{a}\" for a in AA] + [\"Length\"]     # new column names\n",
    "    out = pd.concat([df[[\"ID\", \"Fold\"]],              # keep ID + label\n",
    "                     pd.DataFrame(feats.tolist(), columns=cols)],\n",
    "                    axis=1)\n",
    "    out.to_csv(dst, index=False)                      # save result\n",
    "    print(f\"✓ saved {dst}  (rows={len(out)})\")\n",
    "\n",
    "# Generate features for both datasets\n",
    "make_features(\"data/clean_gramneg.csv\", \"data/features_gramneg.csv\")\n",
    "make_features(\"data/clean_grampos.csv\", \"data/features_grampos.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "32ae7160",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 5-fold CV ===\n",
      "Fold 1: 0.723\n",
      "Fold 2: 0.713\n",
      "Fold 3: 0.745\n",
      "Fold 4: 0.713\n",
      "Fold 5: 0.691\n",
      "Average CV accuracy: 0.717\n",
      "\n",
      "=== 10 % hold-out test ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Fold1      0.818     0.500     0.621        18\n",
      "       Fold2      0.000     0.000     0.000         2\n",
      "       Fold3      0.667     0.952     0.784        21\n",
      "       Fold4      0.750     0.750     0.750        12\n",
      "\n",
      "    accuracy                          0.717        53\n",
      "   macro avg      0.559     0.551     0.539        53\n",
      "weighted avg      0.712     0.717     0.691        53\n",
      "\n",
      "Balanced accuracy: 0.551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Purpose: 1) Train a Random-Forest on the Gram-positive feature table.\n",
    "#          2) Check how good it is with two tests:\n",
    "#               • 5-fold cross-validation on 90 % of the data\n",
    "#               • a final 10 % hold-out test the model never saw\n",
    "#          3) Print the usual classification stats.\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.pipeline        import make_pipeline\n",
    "from sklearn.preprocessing    import StandardScaler\n",
    "from sklearn.ensemble         import RandomForestClassifier\n",
    "from sklearn.metrics          import accuracy_score, balanced_accuracy_score, classification_report\n",
    "\n",
    "# 1) LOAD the numeric features which were made using features.py\n",
    "\n",
    "df = pd.read_csv(\"data/features_grampos.csv\")               # 523 rows × 23 cols\n",
    "X  = df[[c for c in df.columns if c.startswith(\"Frac_\")] +  # 20 fraction columns\n",
    "        [\"Length\"]]                                         # + the Length column\n",
    "y  = df[\"Fold\"]                                             # 4 class labels\n",
    "\n",
    "# 2) RESERVE 10 % as a final “never-seen” test set\n",
    "#    The remaining 90 % is used for cross-validation + training\n",
    "X_tr, X_te, y_tr, y_te = train_test_split(\n",
    "        X, y, test_size=0.10, stratify=y, random_state=42)\n",
    "\n",
    "# 3) BUILD the model pipeline\n",
    "#    • StandardScaler: puts every feature on roughly the same scale\n",
    "#    • RandomForest: 200 decision trees, class_weight=\"balanced\"\n",
    "model = make_pipeline(\n",
    "    StandardScaler(),                      # harmless but keeps numbers nice\n",
    "    RandomForestClassifier(\n",
    "        n_estimators=200,                  # number of trees\n",
    "        class_weight=\"balanced\",           # helps the tiny classes\n",
    "        random_state=42)\n",
    ")\n",
    "\n",
    "# 4) 5-FOLD CROSS-VALIDATION on the 90 % training portion\n",
    "#    We train on 4 slices, validate on the 5th — repeat 5 times.\n",
    "print(\"\\n=== 5-fold CV ===\")\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "cv_scores = []\n",
    "\n",
    "for i, (tr_idx, va_idx) in enumerate(cv.split(X_tr, y_tr), start=1):\n",
    "    model.fit(X_tr.iloc[tr_idx], y_tr.iloc[tr_idx])          # fit on 4/5\n",
    "    preds = model.predict(X_tr.iloc[va_idx])                 # test on 1/5\n",
    "    acc   = accuracy_score(y_tr.iloc[va_idx], preds)\n",
    "    cv_scores.append(acc)\n",
    "    print(f\"Fold {i}: {acc:.3f}\")\n",
    "\n",
    "print(\"Average CV accuracy:\", round(sum(cv_scores)/len(cv_scores), 3))\n",
    "\n",
    "# 5) FINAL TEST — train on ALL 90 % then predict the held-out 10 %\n",
    "model.fit(X_tr, y_tr)\n",
    "y_hat = model.predict(X_te)\n",
    "\n",
    "print(\"\\n=== 10 % hold-out test ===\")\n",
    "print(classification_report(y_te, y_hat, digits=3))\n",
    "print(\"Balanced accuracy:\", round(balanced_accuracy_score(y_te, y_hat), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d2c8132d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 5-fold CV ===\n",
      "Fold 1: 0.681\n",
      "Fold 2: 0.660\n",
      "Fold 3: 0.649\n",
      "Fold 4: 0.596\n",
      "Fold 5: 0.670\n",
      "Average CV accuracy: 0.651\n",
      "\n",
      "=== 10 % hold-out test ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Fold1      0.526     0.556     0.541        18\n",
      "       Fold2      0.000     0.000     0.000         2\n",
      "       Fold3      0.667     0.667     0.667        21\n",
      "       Fold4      0.615     0.667     0.640        12\n",
      "\n",
      "    accuracy                          0.604        53\n",
      "   macro avg      0.452     0.472     0.462        53\n",
      "weighted avg      0.582     0.604     0.593        53\n",
      "\n",
      "Balanced accuracy: 0.472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "##KNN \n",
    "from sklearn.preprocessing    import StandardScaler\n",
    "from sklearn.neighbors        import KNeighborsClassifier\n",
    "from sklearn.metrics          import accuracy_score, balanced_accuracy_score, classification_report\n",
    "\n",
    "# 1) LOAD the numeric features which were made using features.py\n",
    "df = pd.read_csv(\"data/features_grampos.csv\")\n",
    "X  = df[[c for c in df.columns if c.startswith(\"Frac_\")] + [\"Length\"]]  # 21 features\n",
    "y  = df[\"Fold\"]                                                         # 4 class labels\n",
    "\n",
    "# 2) KEEP 10 % aside for a final, independent test\n",
    "X_tr, X_te, y_tr, y_te = train_test_split(\n",
    "        X, y, test_size=0.10, stratify=y, random_state=42)\n",
    "\n",
    "# 3) BUILD the model pipeline\n",
    "#    • StandardScaler: puts every feature on the same scale\n",
    "#    • KNeighborsClassifier: looks at the 3 nearest neighbours\n",
    "model = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    KNeighborsClassifier(n_neighbors=3)  #change here to experiment with different values of k\n",
    ")\n",
    "\n",
    "# 4) 5-FOLD CROSS-VALIDATION on the 90 % training part\n",
    "print(\"\\n=== 5-fold CV ===\")\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "cv_scores = []\n",
    "\n",
    "for i, (tr_idx, va_idx) in enumerate(cv.split(X_tr, y_tr), start=1):\n",
    "    model.fit(X_tr.iloc[tr_idx], y_tr.iloc[tr_idx])          # train on 4 folds\n",
    "    preds = model.predict(X_tr.iloc[va_idx])                 # validate on 1 fold\n",
    "    acc   = accuracy_score(y_tr.iloc[va_idx], preds)\n",
    "    cv_scores.append(acc)\n",
    "    print(f\"Fold {i}: {acc:.3f}\")\n",
    "\n",
    "print(\"Average CV accuracy:\", round(sum(cv_scores)/len(cv_scores), 3))\n",
    "\n",
    "# 5) FINAL TEST — train on all 90 % and predict the held-out 10 %\n",
    "model.fit(X_tr, y_tr)\n",
    "y_hat = model.predict(X_te)\n",
    "\n",
    "print(\"\\n=== 10 % hold-out test ===\")\n",
    "print(classification_report(y_te, y_hat, digits=3))\n",
    "print(\"Balanced accuracy:\", round(balanced_accuracy_score(y_te, y_hat), 3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a3bce318",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "AdaBoostClassifier.__init__() got an unexpected keyword argument 'base_estimator'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtree\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DecisionTreeClassifier\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# For AdaBoost:\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m adaboost_model = \u001b[43mAdaBoostClassifier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m=\u001b[49m\u001b[43mDecisionTreeClassifier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_depth\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_estimators\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m50\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# For Bagging:\u001b[39;00m\n\u001b[32m      8\u001b[39m bagging_model = BaggingClassifier(base_estimator=DecisionTreeClassifier(), n_estimators=\u001b[32m50\u001b[39m)\n",
      "\u001b[31mTypeError\u001b[39m: AdaBoostClassifier.__init__() got an unexpected keyword argument 'base_estimator'"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier, BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# For AdaBoost:\n",
    "adaboost_model = AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=1), n_estimators=50)\n",
    "\n",
    "# For Bagging:\n",
    "bagging_model = BaggingClassifier(base_estimator=DecisionTreeClassifier(), n_estimators=50)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
